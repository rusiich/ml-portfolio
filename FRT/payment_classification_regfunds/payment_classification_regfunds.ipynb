{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi9eXEgIg2hq"
      },
      "source": [
        "## Разметка платежей по соглашниям с регфондами по видам работы\n",
        "\n",
        "\n",
        "\n",
        "## Цель и описание проекта\n",
        "\n",
        "**Задача:**  \n",
        "Автоматизировать процесс определения **вида финансируемых работ** по тексту **назначения платежа** в соглашениях с региональными фондами. Это позволит сократить время ручной разметки и повысить точность учёта расходов по видам работ.\n",
        "\n",
        "**Что было сделано:**\n",
        "- Из большого набора (~66 000 строк за 2020–2025 годы) выделено 2000 строк для ручной разметки.\n",
        "- Обучена модель логистической регрессии, достигнута высокая точность (F1 ≈ 99.87).\n",
        "- Проведено несколько итераций активного обучения: модель предсказывает, человек проверяет, далее модель переобучается.\n",
        "- Выделены случаи, в которых модель не может уверенно сделать прогноз (например, неполные или абстрактные формулировки). Эти данные исключаются из обучения и обрабатываются отдельно.\n",
        "- Получена итоговая таблица с предсказаниями, готовая для аналитики в разрезе соглашений и видов работ.\n",
        "\n",
        "**Итог:**  \n",
        "Создан инструмент для классификации платежей по видам работ с высокой точностью. Он помогает формировать отчёты без участия человека, масштабируется на новые данные, повышает прозрачность процессов и снижает риски ошибок при ручной обработке.\n",
        "\n",
        "Выводы и рекомендации приведены в конце проекта\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxoBF7HNsflb"
      },
      "source": [
        "### Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6q_-L5az7yw",
        "outputId": "7cf3d175-f120-4675-e794-5af2962632a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download ru_core_news_sm -q\n",
        "!pip install xlrd -q\n",
        "!pip install openpyxl -q\n",
        "!pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "urdSaM9ZbCAw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import joblib\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Za3MyQ3U0uvL"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x).replace(',', ' ').replace('.', ','))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTqbb9YAadDC",
        "outputId": "7c30dd98-4d03-492c-e613-63f495a23b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-d437433773b2>:1: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df = pd.read_excel(\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel(\n",
        "    r'platezhi_07042025_.xls',\n",
        "    sheet_name='TDSheet',\n",
        "    header=0,\n",
        "    parse_dates =['Регистратор.Дата']\n",
        ")\n",
        "\n",
        "df.head()\n",
        "data_copy = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypJVQTrMbGms"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3P1CzwdcRy8"
      },
      "outputs": [],
      "source": [
        "# Переименовываем столбцы и отбираем только нужные\n",
        "renaming_dict = {\n",
        "    'Регистратор.Дата': 'date',\n",
        "    'Договор контрагента.Номер договора': 'contract_number',\n",
        "    'Регистратор.Исходный документ.Назначение платежа': 'payment_purpose',\n",
        "    ' В валюте упр. учета': 'expense',\n",
        "    'ВИД работы Сводный бюджет': 'work_type',\n",
        "    'check': 'check' # чек проверки платежа чтобы повторно не проверять\n",
        "}\n",
        "df = df[renaming_dict.keys()]\n",
        "df.rename(columns=renaming_dict, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.duplicated()].head() # Дубликаты убирать не буду"
      ],
      "metadata": {
        "id": "6ECMs312eLQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-ZbJfa7T-_7"
      },
      "outputs": [],
      "source": [
        "df['work_type'] = df['work_type'].str.lower()\n",
        "df['work_type'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywWTedA8oNyy"
      },
      "source": [
        "### Анализ данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bjDEEqgoWhg"
      },
      "outputs": [],
      "source": [
        "# Общие расходы по видам работ\n",
        "df_pivot = df.groupby(['work_type', 'contract_number'])['expense'].sum().reset_index()\n",
        "pivot = df_pivot.pivot_table(\n",
        "    values='expense',\n",
        "    index='work_type',\n",
        "    aggfunc='sum',\n",
        ")\n",
        "pivot['share_%'] = pivot['expense'] / pivot['expense'].sum() * 100\n",
        "print(pivot.sort_values(by='expense'))\n",
        "print('Общие прочие расходы', pivot.query('work_type != \"СМР\"')['expense'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4hj7YKD4yzh"
      },
      "outputs": [],
      "source": [
        "df_pivot['is_other'] = df_pivot['work_type'] != 'СМР'\n",
        "pivot = df_pivot.pivot_table(\n",
        "    values='expense',\n",
        "    index='contract_number',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "\n",
        "other_expense = df_pivot[df_pivot['is_other']].groupby('contract_number')['expense'].sum().rename('other_expense')\n",
        "\n",
        "result = pivot.join(other_expense).fillna(0)\n",
        "result['other_share'] = result['other_expense'] / result['expense'] * 100\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(result.query('other_share < 50')['other_share'], bins=100, edgecolor='black')\n",
        "plt.title('Распределение доли прочих расходов по соглашениям')\n",
        "plt.xlabel('Доля прочих расходов')\n",
        "plt.ylabel('Количество соглашений')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VACU_eudCe6"
      },
      "source": [
        "### Обучение модели без BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sx6qM_jsuHl"
      },
      "source": [
        "#### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TxChSaMtsynt"
      },
      "outputs": [],
      "source": [
        "# выделение тестовой выборки\n",
        "data = df.query('date > \"2021-01-01\" and expense < 0')\n",
        "X = data['payment_purpose']\n",
        "y = data['work_type']\n",
        "X = X.str.lower()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivohNh2NtVfV",
        "outputId": "763c067c-589a-42e7-f542-82fb43db776b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\", disable=['parser', 'ner'])\n",
        "num_cores = os.cpu_count()\n",
        "\n",
        "\n",
        "# функция лемматизации\n",
        "def lemmatize(texts):\n",
        "    lemmatized_texts = []\n",
        "    for doc in nlp.pipe(texts, batch_size=100, n_process=num_cores):\n",
        "        lemmatized_texts.append(\" \".join([token.lemma_ for token in doc]))\n",
        "    return lemmatized_texts\n",
        "\n",
        "\n",
        "# функция очистки текстов\n",
        "def clear_text(text):\n",
        "    text = re.sub(r'[^а-яА-ЯёЁ ]', ' ', text)\n",
        "    clean_text = \" \".join(text.split())\n",
        "    return clean_text\n",
        "\n",
        "# загрузка стоп-слов\n",
        "nltk.download('stopwords')\n",
        "stopwords = list(nltk_stopwords.words('russian'))\n",
        "stopwords.extend(['ндс', 'фзп', 'кф', 'рб', 'фб', 'сумма', 'p', 'р', 'мо', 'соглфзп' ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "is_download = True\n",
        "# предобработка или загрузка данных\n",
        "if is_download:\n",
        "    X_train = pd.read_pickle('X_train_lemmas.pkl')\n",
        "    X_test = pd.read_pickle('X_test_lemmas.pkl')\n",
        "    X = pd.read_pickle('X_lemmas.pkl')\n",
        "else:\n",
        "    # очистка, лемматизация и сохранение тренировочной выборки\n",
        "    X_train = X_train.apply(clear_text) # очистка текста\n",
        "    X_train = X_train.to_frame()\n",
        "    X_train['lemm_text'] = lemmatize(X_train['payment_purpose']) # лемматизация текста\n",
        "    X_train.to_pickle('X_train_lemmas.pkl')\n",
        "\n",
        "    # очистка лемматизация и сохранение тестовой выборки\n",
        "    X_test = X_test.apply(clear_text) # очистка текста\n",
        "    X_test = X_test.to_frame()\n",
        "    X_test['lemm_text'] = lemmatize(X_test['payment_purpose']) # лемматизация текста\n",
        "    X_test.to_pickle('X_test_lemmas.pkl')\n",
        "\n",
        "    X = X.apply(clear_text) # очистка текста\n",
        "    X = X.to_frame()\n",
        "    X['lemm_text'] = lemmatize(X['payment_purpose']) # лемматизация\n",
        "    X.to_pickle('X_lemmas.pkl')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnamNOfq_qby",
        "outputId": "83ff160e-1281-43df-a500-73670b54c0a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 126 ms, sys: 16.7 ms, total: 143 ms\n",
            "Wall time: 142 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0JABS-SYDdBg"
      },
      "outputs": [],
      "source": [
        "# кодирование меток\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AnwVia_6FoG"
      },
      "source": [
        "#### Пайплан"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UhGgAGNN6Jad"
      },
      "outputs": [],
      "source": [
        "# создание пайплайна\n",
        "\n",
        "pipe_final = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), stop_words=stopwords)),\n",
        "    ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "param_grid = [\n",
        "    # словарь для модели LogisticRegression()\n",
        "    {\n",
        "        'models': [LogisticRegression(\n",
        "                      random_state=RANDOM_STATE,\n",
        "                      max_iter=100,\n",
        "                      class_weight='balanced',\n",
        "                      penalty='l2'\n",
        "                  )],\n",
        "        'models__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'models__solver': ['liblinear', 'saga', 'lbfgs'],\n",
        "        'models__class_weight': ['balanced'],\n",
        "        'models__penalty': ['l2']\n",
        "    },\n",
        "\n",
        "    # # Добавление elasticnet регуляризации\n",
        "\n",
        "    {\n",
        "        'models': [LogisticRegression(\n",
        "                      random_state=RANDOM_STATE,\n",
        "                      max_iter=100,\n",
        "                      class_weight='balanced',\n",
        "                      solver='saga'\n",
        "                  )],\n",
        "        'models__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'models__penalty': ['elasticnet'],  # ElasticNet регуляризация\n",
        "        'models__l1_ratio': [0.1, 0.5, 0.7, 0.9, 1.0],  # Соотношение l1 и l2\n",
        "        'models__class_weight': ['balanced'],  # Балансировка классов\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'models': [CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)],\n",
        "        'models__iterations': [100, 200],\n",
        "        'models__learning_rate': [0.03, 0.1],\n",
        "        'models__depth': [4, 6, 8],\n",
        "    }\n",
        "\n",
        "    # словарь для модели RandomForestClassifier()\n",
        "    {\n",
        "        'models': [RandomForestClassifier(\n",
        "                      random_state=RANDOM_STATE,\n",
        "                      class_weight='balanced',\n",
        "                  )],\n",
        "        'models__n_estimators': range(50, 100),  # Количество деревьев в лесу\n",
        "        'models__max_depth': range(2, 10),      # Максимальная глубина дерева\n",
        "    },\n",
        "\n",
        "    # словарь для модели GradientBoostingClassifier\n",
        "    {\n",
        "        'models': [GradientBoostingClassifier(\n",
        "                      random_state=RANDOM_STATE\n",
        "                  )],\n",
        "        'models__n_estimators': range(50, 100, 10),\n",
        "        'models__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'models__max_depth': range(2, 5),\n",
        "    },\n",
        "\n",
        "    # словарь для модели XGBoost\n",
        "    {\n",
        "        'models': [XGBClassifier(\n",
        "                      tree_method='gpu_hist',   # основной параметр\n",
        "                      predictor='gpu_predictor',\n",
        "                      gpu_id=0,\n",
        "                      random_state=RANDOM_STATE,\n",
        "                      use_label_encoder=False,\n",
        "                      eval_metric='logloss'\n",
        "                  )],\n",
        "        'models__n_estimators': range(50, 100, 10),\n",
        "        'models__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'models__max_depth': range(2, 5),\n",
        "        'models__scale_pos_weight': [1, 10, 25],  # Для дисбаланса классов\n",
        "    },\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sksqRESu7xq5",
        "outputId": "57540fa3-84d0-4876-a9dc-940d3d3b404c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 43.4 ms, sys: 0 ns, total: 43.4 ms\n",
            "Wall time: 43 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# поиск оптимальных параметров c помощью RandomizedSearchCV\n",
        "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "randomized_search = RandomizedSearchCV(\n",
        "    pipe_final,\n",
        "    param_grid,\n",
        "    cv=stratified_cv,\n",
        "    scoring='f1_macro',\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    n_iter=10,\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "if is_download:\n",
        "    best_model = joblib.load('best_logistic_model.pkl')\n",
        "else:\n",
        "    randomized_search.fit(X_train['lemm_text'], y_train)\n",
        "    best_model = randomized_search.best_estimator_\n",
        "    joblib.dump(best_model, 'best_logistic_model.pkl')\n",
        "    print('Лучшая модель и её параметры:\\n\\n', randomized_search.best_estimator_)\n",
        "    print ('Метрика лучшей модели на тренировочной выборке:', randomized_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_7_AK2MqnqhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b771dd8-4bf8-407f-f6b4-5548fbabd155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метрика лучшей модели на тестовой выборке: 0.9986325066165143\n"
          ]
        }
      ],
      "source": [
        "# Метрика лучшей модели на тестовой выборке\n",
        "\n",
        "y_pred = best_model.predict(X_test['lemm_text'])\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print ('Метрика лучшей модели на тестовой выборке:', f1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj3eElvfjS8b"
      },
      "source": [
        "Модель показала хорошую метрику на тестовой выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0khMO-ikPr7"
      },
      "source": [
        "### Подготовка данных для ручной проверки меток"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8yRSIa6OiU5"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X['lemm_text'])\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred = pd.Series(le.inverse_transform(y_pred),index=X.index, name='prediction')\n",
        "y_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaXLpkYU1ZBA"
      },
      "outputs": [],
      "source": [
        "X['predict'] = y_pred\n",
        "df['predict'] = X['predict']\n",
        "df['predict'] = df['predict'].fillna(df['work_type'])\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Q364ODZc2J6P"
      },
      "outputs": [],
      "source": [
        "# сохранение непроверенных платежей для ручной проверки\n",
        "df.query('work_type != predict and check == 1').to_excel('mismatched_predictions.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_ylUzaot8W0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed83580c-fd56-4504-d2e6-0f1f7da29bc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# расчет уверенности модели в разметке\n",
        "proba = best_model.predict_proba(X['lemm_text'])\n",
        "classes = best_model.classes_\n",
        "\n",
        "df_proba = pd.DataFrame(proba, columns=classes, index=X.index)\n",
        "df_proba['confidence'] = df_proba[classes].max(axis=1)\n",
        "df_proba.query('confidence <=0.95').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NNc8NtgA3z-H"
      },
      "outputs": [],
      "source": [
        "# формирование реестра для ручной проверки платежей в которых модель не уверена\n",
        "df['confidence'] = df_proba['confidence']\n",
        "df.query('confidence <= 0.97 and work_type == predict and check != 1').to_excel('mismatched_predictions_2.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Am07kKDR3d1q"
      },
      "outputs": [],
      "source": [
        "# реестр случайных платежей для финальной проверки\n",
        "df.query('check != 1').sample(500).to_excel('sample_500_prediction.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Прогнозирование на обученной модели"
      ],
      "metadata": {
        "id": "MAT2d0QDTbeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel(\n",
        "    r'p.xlsx',\n",
        "    sheet_name='TDSheet',\n",
        "    header=0,\n",
        "    parse_dates =['Регистратор.Дата']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOuScYCtdxTt",
        "outputId": "4e650893-24ee-4d48-ab1e-7a110faec9ff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-fb4a8972c9e2>:1: UserWarning: Parsing dates in %d.%m.%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df_new = pd.read_excel(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy = data_copy.rename({'ВИД работы Сводный бюджет' : 'Вид платежа'}, axis=1)"
      ],
      "metadata": {
        "id": "oOD1Go6mw2Jw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбираем список признаков для объединения:\n",
        "common_columns = list(set(df_new.columns) & set(data_copy.columns))\n",
        "\n",
        "\n",
        "# Теперь объединяем, предсказываем только по новым признакам\n",
        "df_result = df_new.merge(\n",
        "    data_copy[['Регистратор.Исходный документ', 'Вид платежа']],\n",
        "    on='Регистратор.Исходный документ',\n",
        "    how='left'\n",
        ")\n",
        "df_result.sample(1)"
      ],
      "metadata": {
        "id": "3r3hTH9hv5S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df_result[df_result['Вид платежа'].isnull()]\n",
        "data = data['Регистратор.Исходный документ.Назначение платежа'].apply(clear_text) # очистка текста\n",
        "data = data.to_frame()\n",
        "data['lemm_text'] = lemmatize(data['Регистратор.Исходный документ.Назначение платежа']) # лемматизация текста\n",
        "data.to_pickle('data_lemmas.pkl')"
      ],
      "metadata": {
        "id": "WEziB2K9wgcf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(data['lemm_text'])\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred = pd.Series(le.inverse_transform(y_pred),index=data.index, name='prediction')\n",
        "df_result['Вид платежа'] = df_result['Вид платежа'].fillna(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-Q65VMwgeWc",
        "outputId": "7712cb9b-54f6-4b4e-ff4f-b709e6889b65"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proba = best_model.predict_proba(data['lemm_text'])\n",
        "classes = best_model.classes_\n",
        "\n",
        "data_proba = pd.DataFrame(proba, columns=classes, index=data.index)\n",
        "data_proba['confidence'] = df_proba[classes].max(axis=1)\n",
        "df_result['confidence'] = data_proba['confidence']"
      ],
      "metadata": {
        "id": "Oy908AU5S7xO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_excel('data_25.04.2025.xlsx')"
      ],
      "metadata": {
        "id": "SnyNz9ppT7Za"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result['Вид платежа'] = df_result['Вид платежа'].str.lower()\n",
        "pivot = df_result.groupby(['Договор контрагента.Номер договора', 'Вид платежа'])[' В валюте упр. учета'].sum()\n",
        "\n",
        "pivot.to_excel('data_pivot.xlsx')"
      ],
      "metadata": {
        "id": "fAZ9GO2AVbMm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы\n",
        "\n",
        "Разработка модели для автоматической разметки назначений платежей по видам работ показала высокую эффективность и практическую применимость. Использованная стратегия — комбинирование ручной разметки, активного обучения и отбора «неуверенных» предсказаний — позволила достичь **F1-метрики 99.87%** на тестовой выборке и сохранить высокое качество на полном датасете.\n",
        "\n",
        "Модель:\n",
        "- Успешно масштабируется на новые данные;\n",
        "- Устраняет необходимость ручной классификации большинства строк;\n",
        "- Сохраняет интерпретируемость (логистическая регрессия позволяет отслеживать, какие слова влияют на решение).\n",
        "\n",
        "Проект реализован с учётом:\n",
        "- Исключения шума (платежей, которые не поддаются автоматической классификации);\n",
        "- Интеграции в бизнес-процесс: итоговый датасет позволяет строить агрегированную аналитику по соглашениям и видам работ;\n",
        "- Возможности контроля качества: включён цикл обратной связи — модель указывает на сомнительные примеры для повторной проверки.\n",
        "\n",
        "### Что можно улучшить:\n",
        "- **Дополнительно использовать методы NLP**: например, TF-IDF или BERT-эмбеддинги для повышения устойчивости к вариативности текстов;\n",
        "- **Добавить категориальные признаки** (например, регион, источник финансирования, номер соглашения), что может повысить точность;\n",
        "- **Развить пайплайн до полноценного сервиса**, с возможностью периодического обновления модели и логгирования качества;\n",
        "- **Интегрировать в BI-систему**, где пользователи смогут видеть распределение платежей по видам работ в реальном времени, включая неуверенные случаи.\n",
        "\n",
        "### Общий вывод:\n",
        "Проект успешно решает задачу классификации по слабоструктурированному тексту. Это позволяет использовать модель в производственной среде для оптимизации рутинной аналитики и повышения точности бюджетного планирования. Подход может быть масштабирован и на другие направления с текстовыми источниками.\n"
      ],
      "metadata": {
        "id": "5Tdf9NMXY9K0"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}